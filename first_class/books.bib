@article{ WOS:000792916700005,
Author = {Cao, Longbing},
Title = {A New Age of AI: Features and Futures},
Journal = {IEEE INTELLIGENT SYSTEMS},
Year = {2022},
Volume = {37},
Number = {1},
Pages = {25-37},
Month = {JAN 1},
DOI = {10.1109/MIS.2022.3150944},
ISSN = {1541-1672},
EISSN = {1941-1294},
ORCID-Numbers = {cao, longbing/0000-0003-1562-9429},
Unique-ID = {WOS:000792916700005},
}

@article{ INSPEC:26098772,
Publication-Type = {J},
Type = {Journal Paper},
Title = {Ai4tech: X-AI enabling X-Tech with human-like, generative,
   decentralized, humanoid and metaverse AI},
Author = {Cao, L.},
Journal = {International Journal of Data Science and Analytics},
Month = {2024},
Year = {2024},
Volume = {18},
Issue = {3},
Pages = {219-38},
ORCID-Numbers = {cao, longbing/0000-0003-1562-9429},
ISSN = {2364-4168},
Identifying-Codes = {[10.1007/s41060-024-00615-9]},
Unique-ID = {INSPEC:26098772},
}
@inproceedings{20252118481317 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform},
journal = {Conference on Human Factors in Computing Systems - Proceedings},
author = {Moreira, Gustavo and Bogucka, Edyta Paulina and Constantinides, Marios and Quercia, Daniele},
year = {2025},
pages = {ACM SIGCHI - },
address = {Yokohama, Japan},
abstract = {<div data-language="eng" data-ev-field="abstract">AI development is shaped by academics and industry leaders - let us call them "influencers"- but it is unclear how their views align with those of the public. To address this gap, we developed an interactive platform that served as a data collection tool for exploring public views on AI, including their fears, hopes, and overall sense of hopefulness. We made the platform available to 330 participants representative of the U.S. population in terms of age, sex, ethnicity, and political leaning, and compared their views with those of 100 AI influencers identified by Time magazine. The public fears AI getting out of control, while influencers emphasize regulation, seemingly to deflect attention from their alleged focus on monetizing AI's potential. Interestingly, the views of AI influencers from underrepresented groups such as women and people of color often differ from the views of underrepresented groups in the public.<br/></div> © 2025 Copyright held by the owner/author(s).},
note = {AI fear;AI governance;AI hope;AI influencer;Empirical ethic;Ethical AI;Interactive platform;Participatory AI ethic;Responsible AI;Value alignment;},
URL = {http://dx.doi.org/10.1145/3706598.3714117},
} 
@book{20251718306431 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2025 Elsevier Inc.},
copyright = {Compendex},
title = {Responsible AI in Practice: A Practical Guide to Safe and Human AI},
journal = {Responsible AI in Practice: A Practical Guide to Safe and Human AI},
author = {Duke, Toju and Giudici, Paolo},
year = {2025},
pages = {1 - 212},
abstract = {<div data-language="eng" data-ev-field="abstract">This book is the first practical book on AI risk assessment and management. It will enable you to evaluate and implement safe and accurate AI models and applications. The book features risk assessment frameworks, statistical metrics and code, a risk taxonomy curated from real-world case studies, and insights into AI regulation and policy, and is an essential tool for AI governance teams, AI auditors, AI ethicists, machine learning (ML) practitioners, Responsible AI practitioners, and computer science and data science students building safe and trustworthy AI systems across businesses, organizations, and universities. The centerpiece of this book is a risk management and assessment framework titled "Safe Human-centered AI (SAFE-HAI)," which highlights AI risks across the following Responsible AI principles: accuracy, sustainability and robustness, explainability, transparency and accountability, fairness, privacy and human rights, human-centered AI, and AI governance. Using several statistical metrics such as Area Under Curve (AUC), Rank Graduation Accuracy, and Shapley values, you will learn to apply Lorenz curves to measure risk and inequality across the different principles and will be equipped with a taxonomy/scoring rubric to identify and mitigate identified risks. This book is a true practical guide and covers a real-world case study using the proposed SAFE-HAI framework. The book will help you adopt standards and voluntary codes of conduct in compliance with AI risk and safety policies and regulations, including those from the NIST (National Institute of Standards and Technology) and EU AI Act (European Commission). What You Will Learn • Know the key principles behind Responsible AI and associated risks • Become familiar with risk assessment frameworks, statistical metrics, and mitigation measures for identified risks • Be aware of the fundamentals of AI regulations and policies and how to adopt them • Understand AI governance basics and implementation guidelines Who This Book Is For AI governance teams, AI auditors, AI ethicists, machine learning (ML) practitioners, Responsible AI practitioners, and computer science and data science students building safe and trustworthy AI systems across businesses, organizations, and universities.<br/></div> © 2025 by Toju Duke and Paolo Giudici.},
key = {Risk assessment},
keywords = {Engineering education;Learning systems;Machine learning;Public policy;Risk management;Safety engineering;Taxonomies;Trusted computing;},
note = {AI governance;AI risk impact assessment;AI risk mitigation;AI safety;AI safety metric;Data ethic;Responsible AI;Risk impact assessments;Risk mitigation;Safety metrics;},
URL = {http://dx.doi.org/10.1007/979-8-8688-1166-1},
} 
@manual{esp-idf,
  title        = {南航电工实验教材},
  author       = {Espressif Systems},
  note         = {ESP-IDF Programming Guide},
  year         = {2023}
}

@book{multisim,
  title     = {数字电子技术基础},
  author    = {张三},
  year      = {2023},
  publisher = {高等教育出版社}
}

@misc{esp32-voice,
  author    = {康田帅},
  title     = {学习笔记（用ESP32做一个实时语音对讲机）},
  year      = {2024},
  howpublished = {\url{https://example.com}},
  note      = {个人博客}
  }